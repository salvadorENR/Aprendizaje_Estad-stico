---
title: "Poner como título los ejercicios que vayas a realizar"
author: "Tu nombre"
date: "La fecha"
---

1. Carga los datos en el entorno de Rstudio a través de la función readRDS. Utilizando el código que consideres (y los datos disponibles), indica qué precio estimarías que tiene una vivienda. A continuación, obtén el histograma de la variable dependiente y comenta el gráfico.
```{r }
library(car)
library(purrr)
library(furrr)
library(dplyr)
library(ggplot2)
library(glmnet)
library(caret)
# Para paralelizar
library(doParallel)
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
```

```{r}
datos<-readRDS("VentaViviendas")
str(datos)
```


2.Realiza una partición del conjunto de datos en entrenamiento (80%) y prueba (20%). Explica a continuación de qué sirve esta partición.
```{r}
set.seed(12345)
trainIndex <- createDataPartition(datos$price, p=0.8, list=FALSE)
data_train <- datos[trainIndex,]
data_test <- datos[-trainIndex,]
```
En este caso la partición sirve para determinar si el modelo explica bien al conjunto de datos probandolo con otro conjunto de datos diferentes de aquellos con los que fue entrenado. A parte de eso, sirve pare determinar si el modelo está sobre entrenado sabiendo si el r cuadrado del conjunto de prueba es mucho mayor que con el grupo de datos de entrenamiento. 

3. A continuación, aplica las 6 combinaciones de selección de variables automática (forward, stepwise y backward junto con los criterios AIC yBIC). ¿Cuántos modelos diferentes se generan? ¿Cuántos parámetros tienen? ¿A qué se deben las diferencias observadas (sobre todo entre los modelos generados con AIC y los generados con BIC)?

```{r}
null<-lm(price~1, data=data_train)
full<-lm(price~., data=data_train)
modeloStepBIC<-step(null, scope=list(lower=null, upper=full), direction="both",
                    k=log(nrow(data_train)))
```

```{r}
modeloStepAIC<-step(null, scope=list(lower=null, upper=full), direction="both",
                    k=2, trace=F)
modeloForwBIC<-step(null, scope=list(lower=null, upper=full), direction="forward",
                    k=log(nrow(data_train)),trace=F)
modeloForwAIC<-step(null, scope=list(lower=null, upper=full), direction="forward",
                    k=2, trace=F)
modeloBackBIC<-step(full, scope=list(lower=null, upper=full), direction="backward",
                    k=log(nrow(data_train)),trace=F)
modeloBackAIC<-step(full, scope=list(lower=null, upper=full), direction="backward",
                    k=2, trace=F)
```

```{r}
modelos<-list(modeloStepBIC,modeloStepAIC,modeloForwBIC,modeloForwAIC,modeloBackBIC,
              modeloBackAIC)
map(modelos,function(x) formula(x)) 

```
```{r}
map_int(modelos,function(x) x$rank)
```
Se generan 6 modelos, con paramétros (ver antes), no importa el método forward,backward y multistep, las variables son las mismas, solo cambia si se hace en función de la AIC y BIC. 



4. Para determinar qué modelo es mejor para estos datos, aplica validación cruzada sobre los modelos diferentes del apartado 3. Determina qué modelo es preferible teniendo en cuenta el R2, la estabilidad y el número de parámetros.

```{r}
modelos<-list(modeloStepBIC, modeloStepAIC)
vcrTodosModelos<-list()
for (i in 1:length(modelos)){
  set.seed(12345)
  vcr<-train(formula(modelos[[i]]), data = data_train,
           method = "lm", 
           trControl = trainControl(method="repeatedcv", number=5, repeats=20)
)
  vcrTodosModelos[[i]]<-vcr
}
names(vcrTodosModelos)<-paste0("Model",1:length(modelos), "_",sapply(modelos,function(x) x$rank))
bwplot(resamples(vcrTodosModelos),metric=c("Rsquared"))
```

5. Para el modelo “ganador”, obtén la estimación del R2 en entrenamiento y prueba, la importancia de las variables y los coeficientes del modelo. Comenta las salidas obtenidas, sin olvidar indicar algo sobre la influencia de las variables input en la objetivo.

R^2 entrenamiento
```{r}
R2(predict(modeloStepBIC,data_train), data_train$price)
```
R^2 Prueba
```{r}
R2(predict(modeloStepBIC,data_test), data_test$price)
```

Importancia de las variables

```{r}
Anova(modeloStepBIC,type = "II")
```

Coeficiente del modelo
```{r}
summary(modeloStepBIC)
```
6. Representa en varios diagramas de dispersión la variable objetivo frente a las input numéricas para comparar la forma real de su relación y cómo se ha plasmado en el modelo de regresión lineal. Comenta los resultados.

```{r}
library(ggplot2)
library(mgcv)

# Lista de variables independientes
vars <- c("superf", "lat", "antig", "floors", "long")

# Crear un gráfico por variable
for (v in vars) {
  p <- ggplot(datos, aes_string(x = v, y = "price")) +
    geom_point(shape = ".", alpha = 0.6) +
    geom_smooth(method = "gam", formula = y ~ s(x, bs = "cs", k = 7), se = FALSE, color = "blue") +
    geom_smooth(method = "lm", se = FALSE, color = "red") +
    theme_minimal() +
    labs(
      title = paste("Relación entre", v, "y price"),
      x = v,
      y = "price"
    )
  print(p)
}

```


7. NUEVO: Discretiza las variables cuantitativas input, construye los correspondientes modelos stepwise BIC y AIC y compara estos modelos con el “ganador” del apartado 4 a través de validación cruzada repetida. Determina si la discretización es recomendable en este caso y, de ser así, analiza el modelo final (estimación del R2 en entrenamiento y prueba, la importancia de las variables y los coeficientes del modelo).

```{r}
data_train_disc<-data_train
data_test_disc<-data_test

vars_to_bin <- names(Filter(is.numeric, datos[, -which(names(datos) == "price")])) 
nbins <- 7 # Se puede cambiar a valores entre 4 y 10
for (var in vars_to_bin) {
  breaks <- unique(quantile(data_train_disc[[var]], probs = seq(0, 1, length.out = nbins + 1)))
  data_train_disc[[paste0(var,"_disc")]] <- cut(data_train_disc[[var]], breaks = breaks, include.lowest = TRUE, right = FALSE)
  data_test_disc[[paste0(var,"_disc")]]  <- cut(data_test_disc[[var]],  breaks = breaks, include.lowest = TRUE, right = FALSE)
}
summary(data_train)
```

```{r}
summary(data_test_disc)

```

```{r}
null_disc<-lm(price~1,data=data_train_disc)
full_disc<-lm(price~.,data=data_train_disc)
modeloStepBIC_disc<-step(null_disc, scope=list(lower=null_disc, upper=full_disc), direction="both",
                    k=log(nrow(data_train_disc)), trace=F)
modeloStepAIC_disc<-step(null_disc, scope=list(lower=null_disc, upper=full_disc), direction="both",
                    k=2, trace=F)
modelos<-list(modeloStepBIC_disc,modeloStepAIC_disc)
map(modelos,function(x) formula(x)) 
```
```{r}
map_int(modelos,function(x) x$rank)

```
```{r}
modelos<-list(modeloStepBIC, modeloStepBIC_disc, modeloStepAIC_disc)
vcrTodosModelos<-list()
for (i in 1:length(modelos)){
  set.seed(12345)
  vcr<-train(formula(modelos[[i]]), data = data_train_disc,
           method = "lm",
           trControl = trainControl(method="repeatedcv", number=5, repeats=20)
)
  vcrTodosModelos[[i]]<-vcr
}
names(vcrTodosModelos)<-paste0("Model",1:length(modelos), "_",sapply(modelos,function(x) x$rank))
bwplot(resamples(vcrTodosModelos), metric=c("Rsquared"))

```

```{r}
summary(resamples(vcrTodosModelos), metric=c("Rsquared"))
```
```{r}
summary(modeloStepBIC_disc)
```

```{r}
summary(modeloStepBIC_disc)
```
```{r}
R2(predict(modeloStepBIC_disc,data_train_disc), data_train_disc$price)
```
```{r}
R2(predict(modeloStepBIC_disc,na.omit(data_test_disc)), na.omit(data_test_disc)$price)
```
```{r}
Anova(modeloStepBIC_disc,type = "II")
```
8.Utilizando los datos de la partición de entrenamiento, realiza las modificaciones precisas para poder construir modelos penalizados con R. Explica por qué es necesario llevar a cabo este paso y en qué consiste.

```{r}
y <- data_train$price
x<-model.matrix(price~., data=data_train)[,-1]
```

9. Construye un modelo LASSO con todos los valores posibles de λ y representa gráficamente los resultados (si copias el código facilitado, cuidado con el ylim). Comenta lo que observes y, basándote en dicha información, explica los fundamentos del modelo.

```{r}
modeloLASSO<-glmnet(x, y, alpha = 1, family = "gaussian")
plot(modeloLASSO, xvar="lambda", main = "LASSO")
```


```{r}
modeloRIDGE<-glmnet(x, y, alpha = 0, family = "gaussian")
plot(modeloRIDGE, xvar="lambda", main = "Ridge")
```




10. Para determinar el modelo penalizado óptimo, aplica validación cruzada en una combinación amplia de α y λ y representa gráficamente los resultados. Indica qué significa la línea horizontal que se añade en el gráfico y comenta los resultados que observas. Determina la combinación de parámetros óptima según la regla 1se.

```{r}
set.seed(1234)
cv.lasso <- cv.glmnet(x, y, nfolds=5, family = "gaussian", alpha = 1, parallel = T)
plot(cv.lasso)
```

```{r}
cv.lasso$lambda.min
```
```{r}
cv.lasso$lambda.1se
```

```{r}
cv.lasso$cvm[cv.lasso$index] # Media
```
```{r}
cv.lasso$cvsd[cv.lasso$index] # Error estandar
```


```{r}
cv.lasso$cvup[cv.lasso$index] # Media + error estandar
```

```{r}
future::plan(multisession, workers=detectCores() - 1)
alphas<-seq(0,1,by=0.1)

set.seed(12345)
tunningEnet<- future_map(alphas, 
                         function(a) cv.glmnet(x,y,nfolds=5,family = "gaussian", alpha=a),
                         .options = furrr_options(seed = T))

plan(sequential)
```

```{r}
resultado <- map_df(1:length(alphas),
                    function(x) {
                      data.frame(
                        alpha = alphas[x],
                        lambda = tunningEnet[[x]]$lambda,
                        numPar = tunningEnet[[x]]$nzero,
                        error_cv = tunningEnet[[x]]$cvm,
                        error_up = tunningEnet[[x]]$cvup,
                        posicion = 1:length(tunningEnet[[x]]$nzero)
                      )
                    }
)

error_1se<- resultado |>
  slice_min(error_cv, n=1) |> pull(error_up)

ggplot(data=resultado, aes(x=posicion, y=error_cv, col=as.factor(alpha)))+
  geom_line()+
  geom_point() +
  geom_hline(yintercept = error_1se)
```

```{r}
resultado |>
  filter(error_cv<=error_1se) |> slice_min(numPar) |> arrange(desc(alpha), desc(lambda))
```


```{r}
modeloLASSOdef<-glmnet(x,y, family = "gaussian", alpha = 1, lambda = 0.3101330)
coef(modeloLASSOdef)
```

```{r}
x_test<-model.matrix(price~., data=data_test)[,-1]
R2(predict(modeloLASSOdef, x), data_train$price)
```
```{r}
R2(predict(modeloLASSOdef, x_test), data_test$price)
```
```{r}
set.seed(12345)
cv_glmnet <- train(
  x = x,
  y = y,
  method = "glmnet", family = "gaussian",
  tuneGrid=expand.grid(.alpha=1,.lambda=0.3101330),
  preProc = c("center", "scale"), 
  trControl = trainControl(method="repeatedcv", number=5, repeats=20)
)
summary(cv_glmnet$resample$Rsquared)
```





```{r}
boxplot(cv_glmnet$resample$Rsquared)
```
