---
title: "Prueba Práctica Tema 1"
author: "Salvador"
date: "27/6/2025"
output: html_document
---

```{r, include=FALSE}
knitr::opts_chunk$set(out.width='70%', fig.align = "center") 
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(global.par = TRUE)
```

Carga de los paquetes necesarios

```{r}
library(caret)
library(stargazer)
library(car)
library(pROC)
library(purrr)
library(furrr)
library(dplyr)
library(ggplot2)
library(glmnet)
# Para paralelizar
library(doParallel)
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
```

Carga de los datos

```{r message=FALSE, warning=FALSE}
#Esto es un ejemplo de código
datos<-readRDS("datosDeathPenalty")
str(datos)

```

```{R}
summary(datos)
```

Como la variable objetivo es binaria, se procederá a codificar

```{R}
datos$PenaMuerte<-as.factor(make.names(datos$PenaMuerte))
table(datos$PenaMuerte)/nrow(datos)
```

Podemos concluir que para la variable objetivo, el 60% de las personas están a favor y un 40% no están a favor de la pena de muerte.

Partición entrenamiento-prueba de los datos.

```{r}
set.seed(12345)
trainIndex <- createDataPartition(datos$PenaMuerte, p=0.8, list=FALSE)
data_train <- datos[trainIndex,]
data_test <- datos[-trainIndex,]
```

4.  Genera un primer modelo de regresión logística binario para la variable “PenaMuerte” con todas las variables independientes disponibles y los datos de entrenamiento. ¿Cuántos parámetros tiene el modelo? ¿Todos los parámetros son significativos al 5%? Indica cuáles no lo son.

```{r}
modeloInicial<-glm(PenaMuerte~., data=data_train, family = binomial)
modeloInicial$rank
summary(modeloInicial)
```

-   ¿Cuántos parámetros tiene el modelo manual?

    -   El modelo tiene 16 parametros

-   ¿Todos los parámetros son significativos al 5%?

    -   No, segun los datos obtenidos unicamente 8 parametros son significativos al 5%. En general los parametros no significativos son los que tienen que ver con la informacion sobre el signo zodiacal, aquellos que trabajan tiempo completo o medio tiempo, asi como las variables que tienen que ver con la region

5.  Con la información del modelo, responde a las siguientes preguntas justificando la respuesta:

Aplica el análisis de tipo II sobre el modelo anterior, explica en qué consiste este análisis y de qué sirve. A continuación, analiza los resultados y extrae las conclusiones pertinentes.

```{r}
Anova(modeloInicial, type = "II")
```

Las variables con mayor peso y en este orden son: confianza en el sistema, raza, Partido politico, condenas previas, sexo.

```{r, warning=FALSE}
stargazer(modeloInicial, type="text", report=('vc*p'))
```

Las variables con mayor peso y en este orden son: confianza en el sistema, raza, Partido politico, condenas previas, sexo.

7.  Construye un nuevo modelo (que llamaremos modelo2) que contenga únicamente las 3 variables más importantes (usa la información del ejercicio anterior para saber cuáles son). ¿Cuántos parámetros tiene? ¿Este nuevo modelo tiene todos sus parámetros significativos?

Con esta información, se procede a construir el modelo 2.

```{r}
modelo2 <-  glm(formula = PenaMuerte ~ Raza + Conf + PartidoPolitico + CondenasPrevias + Sexo, family = binomial, data = data_train)
modelo2$rank
summary(modelo2)
```

```{r}
modelo2$rank
Anova(modelo2,type = "II")
```

Para este modelo todos sus parámetros son significativos, y en total tiene 6.

8.  Obtén los ODDS-ratio e interprétalos (haz una frase completa para cada uno de ellos que pudiera comprender alguien con escasos conocimientos de estadística). Recuerda que si algún parámetro no es significativo la frase correspondiente debe reflejar ese hecho.

```{r}
exp(coef(modelo2))
```
 Las personas hispanas tienen 2.79 veces más probabilidad de apoyar la pena de muerte  en comparación con las personas Afroamericana
 
 los individuos blancos tienen 5.68 veces más probabilidades de estar a favor de la pena de muerte en comparación con las personas Afroamericana
 
 Las personas de otra raza tienen 2.11 veces más probabilidad de apoyar la pena de muerte que las personas Afroamericana
 
 Por cada unidad adicional en la escala de confianza, la probabilidad de apoyar la pena de muerte aumenta 94.7%.
 
 Las personas que se identifican como republicanas tienen 3.47 veces más probabilidades de estar a favor de la pena de muerte que las personas que se identifican con el partido demócrata 
 
 Los hombres tienen 1.57 veces más probabilidades de apoyar la pena de muerte que las mujeres, controlando por el resto de variables.

Las personas que se identifican con otro partido tienen 1.22 veces más probabilidad de apoyar la pena de muerte que los demócratas.

Los republicanos tienen 3.47 veces más probabilidad de apoyar la pena de muerte que los demócratas.

Las personas con condenas previas tienen 63.6% menos probabilidad de apoyar la pena de muerte que quienes no tienen condenas previas.

Los hombres tienen 1.57 veces más probabilidad de apoyar la pena de muerte que las mujeres.






9.  Utilizando los datos de la partición de entrenamiento,

<!-- -->

a.  Obtén la matriz de confusión para el punto de corte de 0.5, así como la tasa de acierto, el índice Kappa, la sensibilidad y la especificidad y explica qué significan.

    ```{r}
    probs <-predict(modelo2, data_train, type="response")

    cm <- confusionMatrix(data=as.factor(ifelse(probs>=0.5,"X1","X0")),reference=data_train$PenaMuerte, positive="X1")

    cm$table
    ```

    ```{r}
    cm$overall[1:2]

    cm$byClass[1:2]
    ```

    **Tenemos una tasa del 81% y un índice Kappa del 0.50 lo cual se considera moderado.**

    Repecto a la sensitividad del 90% y la especificidad del 57% nos indica que hay una clasificación muy buena de los valores positivos (X1), sin embargo la clasificación de los negativos (X0) no es del todo bueno, de cierta forma puede ser mejorable.

b.  Si modificamos el punto de corte por la proporción de eventos (codificados como X1) que hay en los datos, ¿cómo se modifican las medidas del apartado anterior? ¿Tiene sentido?

    Modificando el punto de corte al de la proporción de eventos $X_1 =0.72$ se tiene que:

    ```{r}
    probs <-predict(modelo2, data_train, type="response")

    cm2 <- confusionMatrix(data=as.factor(ifelse(probs>=0.6,"X1","X0")),reference=data_train$PenaMuerte, positive="X1")

    cm2$table
    ```

    ```{r}
    cm2$overall[1:2]
    cm2$byClass[1:2]
    ```

    En general, el índice Kappa no ha tenido mayor afectación, aunque la tasa de acierto se ha visto reducida en 1.3%, ahora tenemos una mejor predicción en los $X_0$ al lograr una especificidad del 66% versus un 57% usando el corte en 0.5. En resumen el modelo ha mejorado un poco.

c.  ¿Qué puedes decir sobre la calidad del modelo a partir de la información proporcionada por la curva ROC?

    ```{r}
    curvaROC<-roc(data_train$PenaMuerte, probs)
    curvaROC$auc
    plot(curvaROC)
    ```

El área bajo la curva ROC se obtiene en un 0.81, lo cual nos indica una buena calidad.

10. Repite el ejercicio anterior utilizando los datos de la partición de prueba, haciendo hincapié en la comparación con los resultados anteriores.

    a.  Obtén la matriz de confusión para el punto de corte de 0.5, así como la tasa de acierto, el índice Kappa, la sensibilidad y la especificidad y explica qué significan.

    ```{r}
    probs <-predict(modelo2, data_test, type="response")

    cm3 <- confusionMatrix(data=as.factor(ifelse(probs>=0.5,"X1","X0")),reference=data_test$PenaMuerte, positive="X1")

    cm3$table
    ```

    ```{r}
    cm3$overall[1:2]

    cm3$byClass[1:2]
    ```

<!-- -->

b.  Si modificamos el punto de corte por la proporción de eventos (codificados como X1) que hay en los datos, ¿cómo se modifican las medidas del apartado anterior? ¿Tiene sentido?

    Modificando el punto de corte al de la proporción de eventos $X_1 =0.72$ se tiene que:

    ```{r}
    cm4<-confusionMatrix(data=as.factor(ifelse(probs>=0.60,"X1","X0")),
                         reference=data_test$PenaMuerte, positive="X1")
    cm4$table
    ```

    ```{r}
    cm4$overall[1:2]

    cm4$byClass[1:2]
    ```

<!-- -->

c.  ¿Qué puedes decir sobre la calidad del modelo a partir de la información proporcionada por la curva ROC?

```{r}
curvaROC<-roc(data_test$PenaMuerte, probs)
curvaROC$auc
plot(curvaROC)
```
```{r}
y <- data_train$PenaMuerte
x<-model.matrix(PenaMuerte~., data=data_train)[,-1]

modeloLASSO<-glmnet(x, y, alpha = 1, family = "binomial")
plot(modeloLASSO, xvar="lambda", ylim=c(-3,3), main = "LASSO")
```


```{r}
future::plan(multisession, workers=detectCores() - 1)
alphas<-seq(0,1,by=0.1)

set.seed(12345)
tunningEnet<- future_map(alphas, 
                         function(a) cv.glmnet(x,y,nfolds=5,family = "binomial",
                                               alpha=a, type.measure="auc"),
                         .options = furrr_options(seed = T))

plan(sequential)

```



```{r}
resultado <- map_df(1:length(alphas),
                    function(x) {
                      data.frame(
                        alpha = alphas[x],
                        lambda = tunningEnet[[x]]$lambda,
                        numPar = tunningEnet[[x]]$nzero,
                        auc_cv = tunningEnet[[x]]$cvm,
                        auc_lo = tunningEnet[[x]]$cvlo,
                        posicion = 1:length(tunningEnet[[x]]$nzero)
                      )
                    }
)

auc_1se<- resultado |>
  slice_max(auc_cv, n=1) |> pull(auc_lo)

ggplot(data=resultado, aes(x=posicion, y=auc_cv, col=as.factor(alpha)))+
  geom_line()+
  geom_point() +
  geom_hline(yintercept = auc_1se)
```

