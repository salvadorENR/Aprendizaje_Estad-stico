---
title: "Ejercicios Logística Binaria 2"
author: "Salvador Enrique Rodríguez Hernández"
date: "22/06/2025"
---

1. Carga los datos en el entorno de Rstudio a través de la función readRDS (nota: como estás trabajando con datos “conocidos” no es necesario revisar el tipo de las variables, pues lo hiciste el primer día, pero se debe hacer siempre que el conjunto de datos es nuevo). Formatea la variable dependiente si fuera necesario.
```{r warning=FALSE, message=FALSE}
library(caret)
library(pROC)
library(car)
library(purrr)
library(furrr)
library(dplyr)
library(glmnet)
# Para paralelizar
library(doParallel)
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
datos<-readRDS("DatosGSS")
str(datos)
datos$Hijos<-as.factor(make.names(datos$Hijos))
table(datos$Hijos)/nrow(datos)
```

2. Realiza una partición del conjunto de datos en entrenamiento (80%) y prueba (20%).
```{r}
set.seed(12345)
trainIndex <- createDataPartition(datos$Hijos, p=0.8, list=FALSE)
data_train <- datos[trainIndex,]
data_test <- datos[-trainIndex,]
```

3. Utilizando los datos de la partición de entrenamiento, construye 6 modelos de regresión logística binaria para la variable Hijos aplicando los 3 métodos de selección de variables estudiados y los 2 criterios de selección a partir de la función step. ¿Cuántos parámetros tienen los modelos? ¿Cuántos modelos diferentes se generan? ¿A qué se deben las diferencias (sobre todo entre los modelos generados con AIC y los generados con BIC)?

```{r message=FALSE,warning=FALSE}
null<-glm(Hijos~1,data=data_train, family=binomial)
full<-glm(Hijos~.,data=data_train, family=binomial)
modeloStepBIC<-step(null, scope=list(lower=null, upper=full), direction="both",
                    k=log(nrow(data_train)), trace=F)
modeloStepAIC<-step(null, scope=list(lower=null, upper=full), direction="both",
                    k=2, trace=F)
modeloForwBIC<-step(null, scope=list(lower=null, upper=full), direction="forward",
                    k=log(nrow(data_train)),trace=F)
modeloForwAIC<-step(null, scope=list(lower=null, upper=full), direction="forward",
                    k=2, trace=F)
modeloBackBIC<-step(full, scope=list(lower=null, upper=full), direction="backward",
                    k=log(nrow(data_train)),trace=F)
modeloBackAIC<-step(full, scope=list(lower=null, upper=full), direction="backward",
                    k=2, trace=F)
modelos<-list(modeloStepBIC,modeloStepAIC,modeloForwBIC,modeloForwAIC,modeloBackBIC,
              modeloBackAIC)
map(modelos,function(x) formula(x)) 
map_int(modelos,function(x) x$rank)

```
Con base en la aplicación de los tres métodos de selección de variables (stepwise, forward y backward) junto con los dos criterios de información (AIC y BIC), se han construido un total de seis modelos de regresión logística binaria para predecir la variable Hijos. Al analizar las fórmulas resultantes, se observa que los modelos generados con el criterio BIC contienen 9 parámetros, mientras que los generados con AIC incluyen 19.

Sin embargo, aunque se han obtenido seis modelos en total, únicamente se generan dos modelos distintos: uno con las variables seleccionadas según BIC y otro con las seleccionadas según AIC. Las diferencias observadas entre los modelos de un mismo criterio se deben únicamente al orden en que se incorporan o eliminan las variables durante el procedimiento, pero las variables finales son las mismas, lo que da lugar a una misma especificación estructural del modelo.

Estas diferencias responden a la naturaleza de los criterios utilizados: el AIC favorece modelos con mejor ajuste in-sample, permitiendo incluir más variables si contribuyen mínimamente a la reducción del error, mientras que el BIC penaliza más fuertemente la complejidad del modelo, resultando en estructuras más parsimoniosas. Por ello, los modelos generados con BIC tienden a ser más simples.


4. Una vez generados los modelos (los de la selección automática y el que creaste manualmente con las variables EstadoCivil, Edad y Raza), se debe determinar cuál es el mejor de todos ellos, para lo cual debes aplicar validación cruzada repetida (utiliza un bucle para simplificar esta tarea).
Genera los boxplots para las 3 medidas (AUC, tasa de acierto e índice Kappa), así como los resúmenes y compara los modelos. ¿Cuál parece ser el mejor? Recuerda que si varios modelos son parecidos en cuanto a capacidad predictiva se debe escoger el más sencillo (el que tenga menos parámetros).

```{r warning=FALSE, message=FALSE}
Manual <- lm(Hijos ~ EstadoCivil + Edad + Raza, data = data_train)
modelos<-list(Manual, modeloStepBIC, modeloStepAIC)
vcrTodosModelos<-list()
for (i in 1:length(modelos)){
  set.seed(12345)
  vcr<-train(formula(modelos[[i]]), data = data_train,
           method = "glm", family="binomial",
           trControl = trainControl(method="repeatedcv", number=5, repeats=20,
                                    summaryFunction=multiClassSummary, 
                                    classProbs=TRUE, savePredictions = TRUE)
)
  vcrTodosModelos[[i]]<-vcr
}
names(vcrTodosModelos)<-paste0("Model",1:length(modelos), "_",sapply(modelos,function(x) x$rank))
bwplot(resamples(vcrTodosModelos), metric=c("AUC", "Kappa", "Accuracy"),
       scales = list(x = list(relation = "free")))

```
```{r}
summary(resamples(vcrTodosModelos), metric=c("AUC", "Kappa", "Accuracy"))
```
Con base en los resultados obtenidos mediante validación cruzada repetida para los tres modelos de regresión logística (el modelo manual y los generados con BIC y AIC), se observa que los valores promedio de las métricas AUC, Accuracy e índice Kappa son bastante similares entre los modelos evaluados. No obstante, el modelo manual (Model1\_6) presenta el valor más bajo de AUC, lo que sugiere una menor capacidad discriminativa en comparación con los otros modelos. Aunque el modelo generado con AIC (Model3\_19) muestra los valores promedio más altos en las tres métricas, la diferencia respecto al modelo generado con BIC (Model2\_9) no es sustancial. Dado que el modelo 2 logra un rendimiento competitivo y al mismo tiempo utiliza menos parámetros que el modelo 3, representa una mejor combinación entre capacidad predictiva y simplicidad. Por tanto, se considera que el modelo generado con BIC es la opción preferible, ya que ofrece una solución equilibrada entre desempeño y parsimonia, lo que facilita su interpretación y reduce el riesgo de sobreajuste.


5. Obtén la matriz de confusión utilizando los datos de la partición de prueba del modelo “ganador”, así como un resumen de sus estadísticos y el AUC. ¿Qué puedes decir de la calidad del modelo?

```{r}
probs_test <-predict(modeloStepBIC,data_test, type="response")
cm_test<-confusionMatrix(data=as.factor(ifelse(probs_test>=0.73,"X1","X0")),
                      reference=data_test$Hijos, positive="X1")
cm_test$table
cm_test$overall[1:2]
cm_test$byClass[1:2]
curvaROC_test<-roc(data_test$Hijos, probs_test)
curvaROC_test$auc
```
Al aplicar el modelo seleccionado sobre los datos de prueba, se obtiene una matriz de confusión con una precisión (accuracy) del 79.06\%, lo cual indica que cerca de 8 de cada 10 observaciones fueron correctamente clasificadas. El índice de Kappa es de 0.512, lo que señala un acuerdo moderado entre las predicciones del modelo y los valores reales, más allá del azar.

El modelo también presenta una buena capacidad de detección para la clase positiva (sensibilidad de 0.813), lo que implica que identifica correctamente un alto porcentaje de los casos con presencia de hijos. Por su parte, la especificidad es de 0.735, lo que sugiere que también mantiene un rendimiento aceptable al clasificar correctamente los casos negativos (sin hijos), aunque ligeramente inferior a la sensibilidad.

Finalmente, el área bajo la curva (AUC) obtenida es de 0.813, valor que respalda la capacidad discriminativa general del modelo. En conjunto, estas métricas indican que el modelo tiene un desempeño sólido y equilibrado para la predicción binaria, mostrando un buen compromiso entre sensibilidad y especificidad.


6. Para finalizar, realiza un análisis de tipo II sobre el modelo, saca las conclusiones oportunas e interpreta los odds-ratio.

```{r}
Anova(modeloStepBIC, type = "II")
summary(modeloStepBIC)
exp(coef(modeloStepBIC))
```

El análisis de varianza tipo II muestra que todas las variables incluidas en el modelo (Estado civil, Edad, Género, Raza y Clase social) resultan estadísticamente significativas en la predicción de la variable dependiente (tener o no hijos), con valores-$p$ menores a 0.001. Esto indica que cada una aporta información relevante incluso después de controlar por las demás. Las pruebas de razón de verosimilitud (LR Chisq) confirman que Estado civil es la variable con mayor impacto, seguida por Edad, Género, Raza y finalmente Clase social.

Al observar los coeficientes estimados y sus odds-ratios correspondientes, se puede interpretar el efecto de cada variable. Por ejemplo, ser soltero disminuye significativamente la probabilidad de tener hijos (odds-ratio $\approx$ 0.11), mientras que tener mayor edad incrementa dicha probabilidad (odds-ratio $\approx$ 1.04 por cada año adicional). En cuanto a la Raza, las categorías White y Other muestran odds-ratios menores a 1, indicando menor probabilidad de tener hijos en comparación con la categoría base. Para Clase social, la categoría Media-alta también reduce significativamente la probabilidad (odds-ratio $\approx$ 0.54), mientras que la categoría Media no presenta un efecto significativo.

En conjunto, estos resultados sugieren que el modelo es sólido en términos explicativos y permite identificar con claridad los perfiles asociados a una mayor o menor probabilidad de tener hijos, siendo especialmente relevantes el Estado civil y la Edad como factores determinantes.


7. Construye un modelo LASSO y otro Ridge con todos los valores posibles de λ y representa gráficamente los resultados. Comenta lo que observes y, basándote en dicha información, explica los fundamentos de ambos modelos incidiendo en sus diferencias.

```{r}
y <- data_train$Hijos
x<-model.matrix(Hijos~., data=data_train)[,-1]

modeloLASSO<-glmnet(x, y, alpha = 1, family = "binomial")
plot(modeloLASSO, xvar="lambda", main = "LASSO")

``` 

```{r}
modeloRIDGE<-glmnet(x, y, alpha = 0, family = "binomial")
plot(modeloRIDGE, xvar="lambda", main = "Ridge")
```
Se construyen dos modelos penalizados, uno con penalización LASSO ($\alpha = 1$) y otro con penalización Ridge ($\alpha = 0$), utilizando todos los valores posibles de $\lambda$. En los gráficos generados se representa cómo varían los coeficientes de las variables predictoras a medida que se incrementa la penalización, expresada en escala logarítmica inversa ($\log(\lambda)$).

En el caso del modelo LASSO, se observa que varios coeficientes se reducen exactamente a cero cuando $\lambda$ alcanza ciertos valores, lo que refleja la capacidad de este método para realizar selección de variables de forma automática. Este comportamiento es útil en contextos donde se desea un modelo más interpretable y con menor complejidad.

Por otro lado, el modelo Ridge muestra una contracción gradual de los coeficientes conforme aumenta $\lambda$, pero sin que estos lleguen a ser exactamente cero. Es decir, aunque los coeficientes se aproximan a cero, todos permanecen activos en el modelo. Esto se debe a que Ridge utiliza una penalización de tipo $L_2$, que reduce la magnitud de los coeficientes sin eliminarlos completamente.

La diferencia fundamental entre ambos métodos radica en el tipo de penalización utilizado: mientras que LASSO ($L_1$) tiende a generar modelos más parsimoniosos al anular coeficientes, Ridge ($L_2$) distribuye la penalización entre todas las variables, lo que puede ser preferible cuando se sospecha que muchas de ellas aportan información útil pero con efectos pequeños. Por lo tanto, la elección entre uno u otro depende del objetivo del análisis y de la estructura de correlación entre las variables predictoras.


8. Para determinar el modelo penalizado óptimo, aplica validación cruzada para una combinación amplia de α y λ y representa gráficamente los resultados. Indica qué significa la línea horizontal que se añade en el gráfico y comenta los resultados que observas.
Determina la combinación de parámetros óptima según la regla 1se y, posteriormente, construye el modelo definitivo.+ comenta su efecto sobre la variable objetivo.

```{r}
future::plan(multisession, workers=detectCores() - 1)
alphas<-seq(0,1,by=0.1)

set.seed(12345)
tunningEnet<- future_map(alphas, 
                         function(a) cv.glmnet(x,y,nfolds=5,family = "binomial",
                                               alpha=a, type.measure="auc"),
                         .options = furrr_options(seed = T))

plan(sequential)

resultado <- map_df(1:length(alphas),
                    function(x) {
                      data.frame(
                        alpha = alphas[x],
                        lambda = tunningEnet[[x]]$lambda,
                        numPar = tunningEnet[[x]]$nzero,
                        auc_cv = tunningEnet[[x]]$cvm,
                        auc_lo = tunningEnet[[x]]$cvlo,
                        posicion = 1:length(tunningEnet[[x]]$nzero)
                      )
                    }
)

auc_1se<- resultado |>
  slice_max(auc_cv, n=1) |> pull(auc_lo)

ggplot(data=resultado, aes(x=posicion, y=auc_cv, col=as.factor(alpha)))+
  geom_line()+
  geom_point() +
  geom_hline(yintercept = auc_1se)
```
```{r}
resultado |>
  filter(auc_cv>=auc_1se) |> slice_min(numPar)|> arrange(desc(alpha), desc(lambda))
```
```{r}
modeloLASSOdef<-glmnet(x,y, family = "binomial", alpha = 0.9, lambda = 0.03859098)
coef(modeloLASSOdef)
```
Para determinar el modelo penalizado óptimo, se aplicó validación cruzada sobre una amplia combinación de valores de $\alpha$ y $\lambda$, evaluando el rendimiento mediante el área bajo la curva (AUC). El gráfico generado representa el valor medio del AUC obtenido para cada combinación de parámetros, agrupado por $\alpha$ y ordenado según la cantidad de variables seleccionadas.

La línea horizontal añadida al gráfico representa el límite inferior del intervalo de confianza del mejor AUC encontrado, y se utiliza como referencia para aplicar la regla 1se. Esta regla consiste en seleccionar, entre todos los modelos con AUC dentro de una desviación estándar del mejor, aquel que utiliza el menor número de parámetros, promoviendo así la parsimonia.

De acuerdo con esta regla, se seleccionó como óptima la combinación $\alpha = 0.9$ y $\lambda = 0.0386$, la cual alcanza un AUC medio de aproximadamente $0.817$, con un límite inferior cercano a $0.803$ y solo 5 variables no nulas. Esta combinación refleja un equilibrio adecuado entre rendimiento predictivo y simplicidad del modelo.

Utilizando los valores óptimos seleccionados, se construyó el modelo penalizado definitivo. Los coeficientes estimados del modelo revelan que solo cinco variables fueron seleccionadas como relevantes:


ClaseSocialMedia-alta: ($\beta \approx -0.026$)
RegionSouth: ($\beta \approx 0.011$)
GeneroMale: ($\beta \approx -0.229$)
Edad: ($\beta \approx 0.018$)
EstadoCivilSoltero: ($\beta \approx -1.599$)


El signo y magnitud de los coeficientes permiten interpretar su efecto sobre la probabilidad de tener hijos:

  Ser hombre disminuye la probabilidad de tener hijos en comparación con ser mujer.
  Tener mayor edad se asocia con una mayor probabilidad de tener hijos.
  Estar soltero reduce considerablemente la probabilidad de tener hijos respecto al grupo de referencia (casado).
  Vivir en la región sur y pertenecer a una clase social media-alta tienen efectos muy pequeños pero significativos dentro del modelo.

El modelo resultante cumple con los objetivos de ser predictivo y parsimonioso, facilitando además la interpretación de las variables más influyentes. Esto evidencia las ventajas del uso de técnicas de regularización como el modelo LASSO, que además de ajustar correctamente, realiza selección automática de variables.


9. Obtén la matriz de confusión utilizando los datos de la partición de prueba del modelo anterior, así como un resumen de sus estadísticos. Calcula también su AUC. ¿Qué puedes decir de la calidad del modelo?


```{r warning=FALSE,message=FALSE}
x_test<-model.matrix(Hijos~., data=data_test)[,-1]

probs_test_enet <-predict(modeloLASSOdef, x_test, type="response")
cm_test_enet<-confusionMatrix(data=as.factor(ifelse(probs_test_enet>=0.73,
                                                    "X1","X0")),
                              reference=data_test$Hijos, positive="X1")
cm_test_enet$table
cm_test_enet$overall[1:2]
cm_test_enet$byClass[1:2]
curvaROC_test_enet<-roc(data_test$Hijos, probs_test_enet)
curvaROC_test_enet$auc
```

El modelo presenta un rendimiento adecuado, con una precisión cercana al 80\% y una buena capacidad de discriminación reflejada por un AUC de aproximadamente 0.79. La sensibilidad es mayor que la especificidad, lo que indica que el modelo tiende a identificar correctamente a los individuos con hijos (clase positiva) con mayor eficacia que a los que no los tienen. El índice Kappa también refleja un nivel moderado de concordancia entre las predicciones y la clasificación real. En conjunto, estos resultados muestran que el modelo tiene una calidad aceptable y puede ser utilizado para propósitos predictivos con cierto nivel de confianza.









